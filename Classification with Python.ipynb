{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#generate simulated classification data\n",
    "def covidData(Nsamp):\n",
    "    # Set seed so we all have the same data \n",
    "     np.random.seed(11) \n",
    "     # age as a uniform value [0,1] \n",
    "     age = np.random.uniform(low=0.0,high=1.0,size=Nsamp) \n",
    "     # Smoke? \n",
    "     smoke = np.random.randint(low=0,high=2,size=Nsamp) \n",
    "     # number of smokers and nonsmokers \n",
    "     nSmoke = np.sum(smoke) \n",
    "     nnSmoke = Nsamp - nSmoke \n",
    "     death = np.zeros(Nsamp,dtype=int) \n",
    "     # Death prob = 0.5 if you don't smoke \n",
    "     death[smoke==0] = (np.random.uniform(size=nnSmoke)<0.5) \n",
    "     # If you do smoke, then it depends quadratically on age \n",
    "     death[smoke==1] = (np.random.uniform(size=(nSmoke))<3./2.*age[smoke==1]**2)\n",
    "     # stack predictor variables in matrix \n",
    "     xPredict = np.stack((age,smoke),axis=1) \n",
    "     return(xPredict, death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Death rate overall is 0.54 \n",
      "Death rate for smokers is 0.58 \n",
      "Death rate for nonsmokers is 0.49\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "#Generate data\n",
    "data = covidData(100)\n",
    "\n",
    "#Central Tendency Measure\n",
    "dr_overall = np.mean(data[-1])\n",
    "dr_smoker = round(np.mean(data[-1][data[0][:,1]==1]),2)\n",
    "dr_nnsmoker = round(np.mean(data[-1][data[0][:,1]==0]),2)\n",
    "\n",
    "print(\"Death rate overall is\", dr_overall, \"\\n\"\n",
    "     \"Death rate for smokers is\", dr_smoker,\"\\n\"\n",
    "     \"Death rate for nonsmokers is\", dr_nnsmoker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "# Monte-carlo evaluation of a training and test data\n",
    "# A function to automate MC experiments\n",
    "def MCtraintest(nmc,X,y,modelObj,testFrac): \n",
    "    trainScore = np.zeros(nmc)\n",
    "    testScore  = np.zeros(nmc)\n",
    "    for i in range(nmc): \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=testFrac)\n",
    "        modelObj.fit(X_train,y_train) \n",
    "        trainScore[i] = modelObj.score(X_train,y_train) \n",
    "        testScore[i]  = modelObj.score(X_test,y_test)\n",
    "    return (trainScore,testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XYF_9\\anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "C:\\Users\\XYF_9\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-440a413369f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtraining_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "nmc = 250\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 31)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    trainScore, testScore = MCtraintest(nmc, X, y, knn, 0.25)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(np.mean(trainScore))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(np.mean(testScore))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"The optimal neighbor size for data is 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for the training sample with one neighbor is. 1.0\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "print(\"The score for the training sample with one neighbor is\", training_accuracy[0],\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on training set: 0.69\n",
      "Accuracy of logistic regression classifier on test set: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nmc = 250\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# build the model\n",
    "logreg = LogisticRegression()\n",
    "trainScore, testScore = MCtraintest(nmc, X, y, logreg, 0.25)\n",
    "print('Accuracy of logistic regression classifier on training set: {:.2f}'.format(np.mean(trainScore)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(np.mean(testScore)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
